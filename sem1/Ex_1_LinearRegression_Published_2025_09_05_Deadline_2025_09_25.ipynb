{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# README: Правила игры\n",
        "\n",
        "## Сроки публикации и сдачи заданий\n",
        "<font size=4>\n",
        "Новые задания к семинарам публикуются каждые две недели, по пятницам нечётных недель (как текущая неделя 01.09.2025-07.09.2025).<br><br>\n",
        "Единый для обеих групп срок сдачи: <b>20 дней</b>, сдача проводится <b>очно</b> по расписанию в дни семинарских занятий, по пятницам в ауд. 8304 на семинарах ШАД-412 и по четвергам в ауд. 8508 на семинарах ШАД-411. Всего под сдачу семинара будет выделено <b>24 академических часа</b> (из них часть будет пересекаться со сдачей следующего семинара). Например: для текущего задания от 05.09.2025 срок сдачи будет истекать 25.09.2025. <br><br>\n",
        "</font>\n",
        "\n",
        "## Заимствование кода\n",
        "<font size=4>\n",
        "<b>Не допускается</b> копировать/заимствовать код:<br>\n",
        "- у другого студента;<br>\n",
        "- из интернета без указания ссылки на первоисточник;<br>\n",
        "- из ответа ChatGPT и аналогов, не понимая, как код работает и без ссылки на первоисточник.<br>\n",
        "При нарушении этих правил баллы обнуляются. Неспособность студента объяснить работу собственного кода на сдаче приравнивается к несоблюдению правил о заимствовании.<br><br>\n",
        "Грамотно заимствовать код из интернета и/или генерировать его можно, но необходимо чётко указать, какой именно участок кода и откуда/где заимствован/сгенерирован, и понимать, как этот участок работает.\n",
        "</font>\n",
        "\n",
        "## Баллы\n",
        "<font size=4>\n",
        "Задания оцениваются баллами. При отчетных мероприятиях (промежуточная аттестация, выдача вопросов на экзамене) учитывается <b>процент</b> от общего числа баллов, причем в общее число баллов не входят семинары, пропущенные по уважительной причине (о пропуске по уважительной причине нужно сообщить преподавателю лично). Баллы выставляются на сдаче, ориентировочные критерии указаны в задании. Задания, не сданные в срок, оцениваются в 0 баллов. Можно заработать дополнительные баллы за выполнение дополнительных заданий.\n",
        "</font>"
      ],
      "metadata": {
        "id": "h2-db7D7Nq0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Семинар 1. Линейная регрессия\n",
        "**Внимание!** В этом семинаре для содержательной части кода (кроме сравнения c `sklearn` в задаче 1.3 и визуализации) разрешается использовать только библиотеку `numpy`. Решения с использованием других библиотек не будут засчитаны.\n",
        "\n"
      ],
      "metadata": {
        "id": "peLiaQBDNh6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1.1 [max = 6 баллов]\n",
        "[1 балл] Сгенерируйте набор признаков $X$: двумерный массив размера $(1000\\times 1)$ из случайных вещественных чисел, равномерно распределённых по промежутку $[0,\\;1)$. Подсказка: может помочь `numpy.random.uniform`"
      ],
      "metadata": {
        "id": "Vqpb9yYMVLwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = # TODO"
      ],
      "metadata": {
        "id": "zTmIrDtMVLDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2 балла] Сгенерируйте набор меток $y$. Для этого сначала введите самостоятельно теоретические коэффициенты будущей модели линейной регрессии $w$, $b$ (два вещественных числа в диапазоне от $1$ до $10$, на ваш вкус), а затем определите одномерный массив $y$ размера $1000$, используя эти коэффициенты и массив признаков $X$."
      ],
      "metadata": {
        "id": "p2bgD4L6WdDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = # TODO\n",
        "b = # TODO\n",
        "\n",
        "y = # TODO"
      ],
      "metadata": {
        "id": "4ZVdqu3iWcT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1 балл] Переопределите массив меток $y$: добавьте к каждому значению случайный гауссов шум со стандартным отклонением $0.1$. Подсказка: может помочь `numpy.random.normal`"
      ],
      "metadata": {
        "id": "UyEpLVnkXWHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = y + #TODO"
      ],
      "metadata": {
        "id": "lUweHbaiSf0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2 балла] Визуализируйте получившийся датасет $(X, y)$: нанесите точки из датасета на график, подпишите оси, выберите удобный диапазон значений для осей."
      ],
      "metadata": {
        "id": "ouigAYKHYSMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "y7YsJqx6YRZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1.2 [max = 15 баллов]\n",
        "\n",
        "Обозначим за $x_i$ элемент в первом (и единственном) столбце $i$-ой строке массива $X$, за $y_i$ - элемент в $i$-ой строке массива $y$. Согласно рассмотренному на лекции, в задаче линейной регрессии оптимальные параметры $w$ и $b$ определяются из условия\n",
        "\n",
        "$$ \\sum_i \\left(y_i - w x_i - b\\right)^2 = \\min,$$\n",
        "\n",
        "что эквивалентно\n",
        "\n",
        "$$ \\frac{\\partial }{\\partial b}\\sum_i \\left(y_i - w x_i - b\\right)^2 = 0\\quad\\text{и}\\quad  \\frac{\\partial }{\\partial w}\\sum_i \\left(y_i - w x_i - b\\right)^2=0.$$"
      ],
      "metadata": {
        "id": "pVzc3qqfYsEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3 балла] Вычислите аналитически производные в левых частях приведенных выше уравнений (по аналогии с лекцией)"
      ],
      "metadata": {
        "id": "7fKZDoQnZsWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Запишите своё решение ниже (либо в тетради от руки, и тетрадь предъявите при сдаче). Для формул можно использовать $\\LaTeX$:\n",
        "```\n",
        "$[ваша формула среди строки]$\n",
        "$$[ваша формула на отдельной строке]$$\n",
        "```\n",
        "<font color=377E22>\\# TODO</font>\n"
      ],
      "metadata": {
        "id": "HwjBjhHtZ3uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2 балла] Запишите получившуюся систему линейных уравнений относительно $w$ и $b$ в матричном виде"
      ],
      "metadata": {
        "id": "ccXPqdvfaVq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запишите своё решение ниже (либо в тетради от руки, и тетрадь предъявите при сдаче).\n",
        "\n",
        "<font color=377E22>\\# TODO</font>"
      ],
      "metadata": {
        "id": "MsQKrldUbRE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5 баллов] Решите получившуюся систему линейных уравнений, то есть получите оптимальные коэффициенты $\\hat{w}$ и $\\hat{b}$ как формулы, зависящие от $x_i$, $y_i$. При любых ли $x_i$, $y_i$ существует единственное решение? Почему?"
      ],
      "metadata": {
        "id": "1gzO_TC9auP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запишите своё решение ниже (либо в тетради от руки, и тетрадь предъявите при сдаче).\n",
        "\n",
        "<font color=377E22>\\# TODO</font>"
      ],
      "metadata": {
        "id": "6pNwJ0WKafJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2 балла] Пользуясь вашими формулами для $\\hat{w}$ и $\\hat{b}$, вычислите их для вашего датасета. Сравните с теоретическими $w$ и $b$"
      ],
      "metadata": {
        "id": "ouZv-x3lbfrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_optimal = # TODO\n",
        "b_optimal = # TODO"
      ],
      "metadata": {
        "id": "ueFFbr66btfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3 балла] Изобразите на одном графике:\n",
        "\n",
        "- точки датасета\n",
        "- теоретическую линию (с использованием теоретических $w$, $b$)\n",
        "- оптимальную линию по результатам линейной регрессии (с использованием оптимальных $\\hat{w}, \\hat{b}$)\n",
        "\n",
        "Подпишите оси и линии, выберите удобный диапазон значений для осей."
      ],
      "metadata": {
        "id": "h9zBcstub0Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "uJrPXFd_b1k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1.3 [max = 19 баллов]\n",
        "\n",
        "Реализуйте предложенный ниже шаблон класса линейной регресиии `numpyLinearRegression` для произвольного количества признаков. Используйте формулы из лекции и `numpy.linalg`.\n",
        "\n",
        "Проверьте работу класса на вашем датасете, убедитеcь, что оптимальные параметры $\\hat{w}$ и $\\hat{b}$ получаются те же самые (или разберитесь, почему это не так). Сравните результаты с `sklearn.linear_model.LinearRegression`.\n",
        "\n"
      ],
      "metadata": {
        "id": "1r14M_kdcvTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4 балла] добавляется, если решение запускается без ошибки выполнения на ваших данных\n",
        "\n",
        "[1 балл] добавляется, если реализовано сравнение вашего ответа с ответом для `sklearn.linear_model.LinearRegression`\n",
        "\n",
        "[4 балла] добавляется, если решение для вашей модели на ваших данных сходится с ответом `sklearn.linear_model.LinearRegression`\n",
        "\n",
        "[5 баллов] добавляется, если решение полностью векторизовано (нет циклов)\n",
        "\n",
        "[5 баллов] добавляется, если в решении обрабатывается случай, когда не существует обратная матрица, выводится соответствующее предупреждение и вычисления прерываются (либо продолжаются иначе на ваше усмотрение)"
      ],
      "metadata": {
        "id": "901lLH2Udrqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class numpyLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.coef_ = None       # массив, который будет хранить веса при признаках X\n",
        "        self.intercept_ = None  # свободный параметр\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "            X: numpy.ndarray (n_samples, n_features)\n",
        "            y: numpy.ndarray (n_samples)\n",
        "        \"\"\"\n",
        "        # реализуйте процедуру решения системы линейных алгебраических уравнений (см. например np.linalg)\n",
        "        # обновите self.coef_ и self.intercept_\n",
        "\n",
        "        # TODO\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "            X: numpy.ndarray (n_samples, n_features)\n",
        "        \"\"\"\n",
        "        # реализуйте процедуру предсказания y_pred по известному X\n",
        "\n",
        "        # TODO\n",
        "        pass"
      ],
      "metadata": {
        "id": "WoQ9qbWCcx_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# реализуйте проверку на ваших данных\n",
        "# TODO"
      ],
      "metadata": {
        "id": "8BYDZl7jehKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1.4* [max = 10 дополнительных баллов]\n",
        "\n",
        "Выше мы поработали с задачей **дискриминации**, то есть по $X$ предсказывали $y$. Рассмотрите обратную задачу **генерации**, когда линейная модель предсказывает $X$, зная $y$:\n",
        "\n",
        "$$x_i = y_i w_g + b_g$$\n",
        "\n",
        "[3 балла] Найдите оптимальные $\\hat{w}_g$, $\\hat{b}_g$ аналогично со стандартной линейной регрессией (аналитически)\n",
        "\n",
        "[1 балл] Выразите оптимальные $\\hat{w}$ и $\\hat{b}$ через $\\hat{w}_g$, $\\hat{b}_g$ (аналитически).\n",
        "\n",
        "[4 баллов] Реализуйте поиск оптимальных параметров генеративной модели (достаточно для одного признака) в коде. Реализуйте в той же модели предсказание $y$ с оптимальными параметрами. Сравните с аналитическими результатами.\n",
        "\n",
        "[2 балла] Визуализируйте на одном графике датасет и линии-предсказания для дискриминативной и генеративной модели. Подпишите оси и линии, выберите удобный диапазон значений для осей."
      ],
      "metadata": {
        "id": "CXKLvQC7e0-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "YcsSselHe7Bz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}